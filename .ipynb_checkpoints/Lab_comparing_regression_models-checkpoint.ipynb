{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206b259f",
   "metadata": {},
   "source": [
    "**In this final lab, we will model our data. Import sklearn train_test_split and separate the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9feead59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import getpass  # To get the password without showing the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73779be8",
   "metadata": {},
   "source": [
    "**Load the csv. Use the variable customer_df as customer_df = pd.read_csv().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb96efa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('we_fn_use_c_marketing_customer_value_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c8d579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>State</th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Response</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Education</th>\n",
       "      <th>Effective To Date</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Monthly Premium Auto</th>\n",
       "      <th>Months Since Last Claim</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Number of Policies</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Renew Offer Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Total Claim Amount</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Vehicle Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BU79786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2763.519279</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/24/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>56274</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Married</td>\n",
       "      <td>69</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>384.811147</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QZ44356</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6979.535903</td>\n",
       "      <td>No</td>\n",
       "      <td>Extended</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1/31/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Single</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer3</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1131.464935</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI49188</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>12887.431650</td>\n",
       "      <td>No</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/19/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>48767</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Married</td>\n",
       "      <td>108</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>566.472247</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WW63253</td>\n",
       "      <td>California</td>\n",
       "      <td>7645.861827</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1/20/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Married</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>529.881344</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HB64268</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2813.692575</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/3/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>43836</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Single</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L1</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>138.130879</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer       State  Customer Lifetime Value Response  Coverage Education  \\\n",
       "0  BU79786  Washington              2763.519279       No     Basic  Bachelor   \n",
       "1  QZ44356     Arizona              6979.535903       No  Extended  Bachelor   \n",
       "2  AI49188      Nevada             12887.431650       No   Premium  Bachelor   \n",
       "3  WW63253  California              7645.861827       No     Basic  Bachelor   \n",
       "4  HB64268  Washington              2813.692575       No     Basic  Bachelor   \n",
       "\n",
       "  Effective To Date EmploymentStatus Gender  Income Location Code  \\\n",
       "0           2/24/11         Employed      F   56274      Suburban   \n",
       "1           1/31/11       Unemployed      F       0      Suburban   \n",
       "2           2/19/11         Employed      F   48767      Suburban   \n",
       "3           1/20/11       Unemployed      M       0      Suburban   \n",
       "4            2/3/11         Employed      M   43836         Rural   \n",
       "\n",
       "  Marital Status  Monthly Premium Auto  Months Since Last Claim  \\\n",
       "0        Married                    69                       32   \n",
       "1         Single                    94                       13   \n",
       "2        Married                   108                       18   \n",
       "3        Married                   106                       18   \n",
       "4         Single                    73                       12   \n",
       "\n",
       "   Months Since Policy Inception  Number of Open Complaints  \\\n",
       "0                              5                          0   \n",
       "1                             42                          0   \n",
       "2                             38                          0   \n",
       "3                             65                          0   \n",
       "4                             44                          0   \n",
       "\n",
       "   Number of Policies     Policy Type        Policy Renew Offer Type  \\\n",
       "0                   1  Corporate Auto  Corporate L3           Offer1   \n",
       "1                   8   Personal Auto   Personal L3           Offer3   \n",
       "2                   2   Personal Auto   Personal L3           Offer1   \n",
       "3                   7  Corporate Auto  Corporate L2           Offer1   \n",
       "4                   1   Personal Auto   Personal L1           Offer1   \n",
       "\n",
       "  Sales Channel  Total Claim Amount  Vehicle Class Vehicle Size  \n",
       "0         Agent          384.811147   Two-Door Car      Medsize  \n",
       "1         Agent         1131.464935  Four-Door Car      Medsize  \n",
       "2         Agent          566.472247   Two-Door Car      Medsize  \n",
       "3   Call Center          529.881344            SUV      Medsize  \n",
       "4         Agent          138.130879  Four-Door Car      Medsize  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bdba2",
   "metadata": {},
   "source": [
    "**What should we do with the customer_id column?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc7a9f4",
   "metadata": {},
   "source": [
    "*We have to drop customer_id columnn as it doesn't add value to dataset. Also 'Policy Type' is redundant and the same as 'Policy'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ab80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = customer_df.drop(['Customer', 'Policy Type'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875aae6",
   "metadata": {},
   "source": [
    "**Load the continuous and discrete variables into numericals_df and categorical_df variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfe4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkhat\\AppData\\Local\\Temp\\ipykernel_15904\\3522850787.py:2: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  categorical = customer_df.select_dtypes(np.object)\n"
     ]
    }
   ],
   "source": [
    "numerical = customer_df.select_dtypes(np.number)\n",
    "categorical = customer_df.select_dtypes(np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c098f46",
   "metadata": {},
   "source": [
    "**Plot every categorical variable. What can you see in the plots? Note that in the previous lab you used a bar plot to plot categorical data, with each unique category in the column on the x-axis and an appropriate measure on the y-axis. However, this time you will try a different plot. This time in each plot for the categorical variable you will have, each unique category in the column on the x-axis and the target(which is numerical) on the Y-axis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121261e1",
   "metadata": {},
   "source": [
    "*Here it can be seen that the 'marital status' has a more normal distribution compared to the others. In terms of visualization, 'Policy' and 'Effective To Date' don't have an acceptable appearance. Therefore, bucketing can be used to group them*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff79f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['Policy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12cc04",
   "metadata": {},
   "source": [
    "*It can be grouped into 5 groups. values whose count is less than 1014 can be considered one group.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placing the value_counts of policy in a new dataframe to be able to define a function and group them\n",
    "vals_policy = pd.DataFrame(customer_df['Policy'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a43c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_policy = vals_policy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining 2 columns for the datafram\n",
    "vals_policy.columns = ['Policy', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa60035",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_policy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the policies less than 1014 into one group\n",
    "vals_policy_new = vals_policy[vals_policy['Count'] < 1014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9e8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals_policy_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd3ec9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#converting the grouped dataframe into a list to define the function\n",
    "vals_policy_new = list(vals_policy_new['Policy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_policy_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function\n",
    "def policy_cleaner(x):\n",
    "    if x in vals_policy_new:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the function\n",
    "customer_df['Policy'] = customer_df['Policy'].apply(policy_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the function works properly\n",
    "customer_df['Policy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e47a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df['Policy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4fdbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='Policy', y=\"Total Claim Amount\", data=customer_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbe3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df['Policy'] = customer_df['Policy'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4edcf3",
   "metadata": {},
   "source": [
    "*Now the 'Policy' column has a better visualization. The same can be done with 'Effective To Date' column*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39975df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the values of 'Effective to Date' to decide how to group the data\n",
    "customer_df['Effective To Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab77b84",
   "metadata": {},
   "source": [
    "*The values are between Jan and Feb. So the data can be divided into 2 groups of only Jan and Feb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the format of the column to datetime\n",
    "vals_effective = pd.to_datetime(customer_df['Effective To Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to divide the data into two groups of Jan or Feb\n",
    "def date_divider(x):\n",
    "        if x.month == 1:\n",
    "            return 'Jan'\n",
    "        else:\n",
    "            return 'Feb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function to dataframe\n",
    "vals_effective = vals_effective.apply(date_divider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data in the format of a dataframe\n",
    "vals_effective = pd.DataFrame(vals_effective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01610426",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_effective.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac589cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assining the divided groups into the 'Effective To Date' column\n",
    "customer_df['Effective To Date'] = vals_effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7fec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c402c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df['Effective To Date'] = customer_df['Effective To Date'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1e2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checkin if the visualization has improved\n",
    "sns.barplot(x='Effective To Date', y=\"Total Claim Amount\", data=customer_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cbf4e",
   "metadata": {},
   "source": [
    "*It can be seen that the column visualization has improved after grouping the data only into two groups compared to the previous plot.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02168712",
   "metadata": {},
   "source": [
    "*Checking the values of Vehicle Class', this column also can be dealt with bucketing method as there are values with less frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3603d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_df['Vehicle Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_size = pd.DataFrame(customer_df['Vehicle Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ea89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_size = vals_size.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_size.columns = ['Vehicle Class', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_size_new = vals_size[vals_size['Count'] < 1796]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844eeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_size_new = list(vals_size_new['Vehicle Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258162d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_cleaner(x):\n",
    "    if x in vals_size_new:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25af5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['Vehicle Class'] = customer_df['Vehicle Class'].apply(size_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7848135",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "customer_df['Vehicle Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df['Vehicle Class'] = customer_df['Vehicle Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15a958",
   "metadata": {},
   "source": [
    "**For the categorical data, check if there is any data cleaning that need to perform. Hint: You can use the function value_counts() on each of the categorical columns and check the representation of different categories in each column. Discuss if this information might in some way be used for data cleaning.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f089a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe74c7e",
   "metadata": {},
   "source": [
    "*After doing the value_counts() and checking for the null values, there are no columns with null values that need to be dropped or fixed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e07d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the outliers after bucketing some columns:\n",
    "for i in categorical_df:\n",
    "    sns.boxplot(data=customer_df, x=i, y='Total Claim Amount', whis = 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ac5fe",
   "metadata": {},
   "source": [
    "**Summary: After checking the boxplot and bars for categorical data, it can be seen that there are some outliers in categorical columns. However, there isn't a process to deal with outliers of categorical columns as they aren't numerica values. One way, as it has been done before can be using value_counts() and bucketing the least frequent values in another group in order to have a more balanced data and less outliers when compared to the target.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c207426",
   "metadata": {},
   "source": [
    "# Lab Feature Extraction Starting From here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65fe5b",
   "metadata": {},
   "source": [
    "**Plot all the categorical variables with the proper plot. What can you see?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a26fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using count plot to show the categoricals in a bar plot\n",
    "for i in categorical_df:\n",
    "    categorical_df[i].value_counts().plot(kind='bar', xlabel=i, ylabel='count', rot=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfbab2e",
   "metadata": {},
   "source": [
    "*It can be seen that the 'Gender' column has almost the same number of F and M values. Therefore, it won't affect the results and we can drop thos column. Furthermore, the data that has been used here is the one before bucketing. Thus, some columns such as 'effective to date' and 'policy' and 'vehicle class' need to be cleaned. This has been done in the previous lab. Moreover, the column of 'policy type' the value of 'special auto' has a very low number compared to two other groups. Grouping can also be used for this column too.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a01290",
   "metadata": {},
   "source": [
    "**There might be some columns that seem to be redundant, check their values to be sure. What should we do with them?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435617c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the values of 'Gender'\n",
    "customer_df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9824c",
   "metadata": {},
   "source": [
    "*As can be seen both from counting the values and the plots, gender column has approximately the same number of values and can be dropped as it won't affect the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6381125",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = customer_df.drop(['Gender'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df = categorical_df.drop(['Gender'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110efc5f",
   "metadata": {},
   "source": [
    "**Plot time variable. Can you extract something from it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c45c9b",
   "metadata": {},
   "source": [
    "*Assuming that time variable is the same as 'Effective To Date' column, it can be seen that this column has many values. However, despite the fact that there are many days, there are only 2 months: Jan and Feb and the year is the same. So, we can conduct feature extraction technique here to extract the month with the highes frequencies which can also be correlated to the months with the highest total claim amunt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eecec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting data to datetime format\n",
    "vals_df = pd.to_datetime(customer_df['Effective To Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the frequency of values\n",
    "vals_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32091d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe with the value_counts of the values\n",
    "date_df = pd.DataFrame(vals_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93554f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0712921",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a15618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining 2 columns for the previous dataset\n",
    "date_df.columns = ['Effective To Date', 'Counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35375211",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f890c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the condition for the high frequency(Considering that more than 170 is considered a high frequency)\n",
    "vals_effective_max = date_df[date_df['Counts'] > 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35436b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_effective_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c65731",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_effective_max_new = list(vals_effective_max['Effective To Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfe4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_effective_max_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b09352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function to retunr the months with the highest frequency\n",
    "def month_extracter(x):\n",
    "    if x in vals_effective_max_new:\n",
    "        return x.month\n",
    "    else:\n",
    "        return 'not high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function\n",
    "vals_df = vals_df.apply(month_extracter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c1a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd216245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344cfa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals_df.value_counts().plot(kind='bar', xlabel='Effective To Date', ylabel='count', rot=0)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e1ba8d",
   "metadata": {},
   "source": [
    "**Summary: It can be seen from the plot that the month with the highest frequency was January.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff1fc7",
   "metadata": {},
   "source": [
    "# Lab data cleaning and wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04639bd0",
   "metadata": {},
   "source": [
    "**We will start with removing outliers. So far, we have discussed different methods to remove outliers. Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bc4ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['Number of Open Complaints'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the outliers in numerical columns:\n",
    "for i in numerical_df:\n",
    "    sns.boxplot(data=customer_df, x=i, whis = 8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6eea89",
   "metadata": {},
   "source": [
    "*The columns of 'Customer Lifetime Value', 'Monthly Premium Auto', 'Total Claim amount' have the highest number of outliers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the null values to see if they have been considered as outliers\n",
    "customer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the iqr\n",
    "iqr = np.percentile(numerical_df['Customer Lifetime Value'],75) - np.percentile(numerical_df['Customer Lifetime Value'],25) # measuring the iqr of the column\n",
    "iqr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the limits\n",
    "upper_limit = np.percentile(numerical_df['Customer Lifetime Value'],75) + 8*iqr\n",
    "lower_limit = np.percentile(numerical_df['Customer Lifetime Value'],25) - 8*iqr\n",
    "upper_limit, lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function to remove outliers:\n",
    "def outliers_remover(customer_df, threshold=1.5, in_columns=numerical_df.columns, skip_columns=[]):\n",
    "    for column in in_columns:\n",
    "        if column not in skip_columns:\n",
    "            upper = np.percentile(customer_df[column],75)\n",
    "            lower = np.percentile(customer_df[column],25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + threshold * iqr\n",
    "            lower_limit = lower - threshold * iqr\n",
    "            customer_df = customer_df[(customer_df[column]>lower_limit) & (customer_df[column]<upper_limit)]\n",
    "    return customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function and changing the threshold:\n",
    "customer_df1 = outliers_remover(customer_df, threshold=4, skip_columns=['Income', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853e926",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(customer_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832351f",
   "metadata": {},
   "source": [
    "*The number of deleted rows is 274 which isn't very high compared to the whole number of row.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the outliers in categorical columns vs the numerical continous target\n",
    "for i in categorical_df:\n",
    "    sns.boxplot(data=customer_df1, x=i, y='Total Claim Amount', whis = 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f4054",
   "metadata": {},
   "source": [
    "*After deleting the outliers of 'total claim amount', the categorical data looks fine in case of outliers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e643dc7",
   "metadata": {},
   "source": [
    "**Create a copy of the dataframe for the data wrangling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2 = customer_df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021a658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_df2 = customer_df2.select_dtypes(np.number)\n",
    "categorical_df2 = customer_df2.select_dtypes(np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9a7a3",
   "metadata": {},
   "source": [
    "**Normalize the continuous variables. You can use any one method you want.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the distributions of numericals\n",
    "for column in numerical_df:\n",
    "    sns.distplot(customer_df2[column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying box cox transformation\n",
    "import scipy.stats as stats\n",
    "\n",
    "def boxcox_transform(X):\n",
    "    numeric_cols = customer_df2.select_dtypes(np.number).columns\n",
    "    _ci = {column: None for column in numeric_cols}\n",
    "    for column in numeric_cols:\n",
    "        # since i know any columns should take negative numbers, to avoid -inf in df\n",
    "        customer_df2[column] = np.where(customer_df2[column]<=0, np.NAN, customer_df2[column]) \n",
    "        customer_df2[column] = customer_df2[column].fillna(customer_df2[column].mean())\n",
    "        transformed_data, ci = stats.boxcox(customer_df2[column])\n",
    "        customer_df2[column] = transformed_data\n",
    "        _ci[column] = [ci] \n",
    "    return customer_df2, _ci\n",
    "customer_df2, _ci = boxcox_transform(customer_df2)\n",
    "customer_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_df:\n",
    "    sns.distplot(customer_df2[column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378f8c9",
   "metadata": {},
   "source": [
    "**Encode the categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5558a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding using ordinal encoding:\n",
    "customer_df2[\"Coverage\"] = customer_df2[\"Coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35934c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one Hot encoding using 4 different columns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "columns_to_one_hot = ['State','Marital Status','Policy Type','Policy', 'Renew Offer Type', 'Sales Channel', 'Response', 'Vehicle Class']\n",
    "encoded_array = enc.fit_transform(customer_df2.loc[:,columns_to_one_hot])\n",
    "categoricals_encoded = pd.DataFrame(encoded_array,columns=enc.get_feature_names_out() )\n",
    "customer_df2 = pd.concat([customer_df2,categoricals_encoded],axis=1)\n",
    "customer_df2.drop(labels= columns_to_one_hot,axis=1,inplace=True)\n",
    "customer_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a32e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2['EmploymentStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e298bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2[\"EmploymentStatus\"] = customer_df2[\"EmploymentStatus\"].map({\"Employed\" : 4, \"Medical Leave \" : 3, \"Disabled\" : 2, \"Retired\" : 1, 'Unemployed' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2['Location Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2[\"Location Code\"] = customer_df2[\"Location Code\"].map({\"Urban\" : 3, \"Rural\" : 2, \"Suburban\" : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2['Vehicle Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5eb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2[\"Vehicle Size\"] = customer_df2[\"Vehicle Size\"].map({\"Large\" : 3, \"Medsize\" : 2, \"Small\" : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed5617",
   "metadata": {},
   "source": [
    "**The time variable can be useful. Try to transform its data into a useful one. Hint: Day week and month as integers might be useful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2452c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the format of the column to datetime\n",
    "vals_effective = pd.to_datetime(customer_df2['Effective To Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c510b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the day data in a seperate column\n",
    "customer_df2['day'] = vals_effective.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the month data in a seperate column\n",
    "customer_df2['month'] = vals_effective.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc28ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function for deriving the week\n",
    "def week_finder(x):\n",
    "    if x <= 7:\n",
    "        return 1\n",
    "    elif 7<x<=14:\n",
    "        return 2\n",
    "    elif 14<x<21:\n",
    "        return 3\n",
    "    elif 21<x<=28:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function on day column and defining a new column for the week column\n",
    "customer_df2['week'] = customer_df2['day'].apply(week_finder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876263fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2['week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9333cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864fc961",
   "metadata": {},
   "source": [
    "**Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6291d",
   "metadata": {},
   "source": [
    "*The only column that needs to be encoded is the 'Education' column. Ordinal encoding can be used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2[\"Education\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bfed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinal encoding\n",
    "customer_df2[\"Education\"] = customer_df2[\"Education\"].map({\"Doctor\" : 5, \"Master\" : 4, \"Bachelor\" : 3, \"College\" : 2, \"High School or Below\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27947979",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4918f",
   "metadata": {},
   "source": [
    "*as we have extracted the required data from effective to date, this column now can be dropped. Also, gender column can be dropped like before.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e839912",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2 = customer_df2.drop(['Effective To Date', 'Gender'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e286176",
   "metadata": {},
   "source": [
    "*The Nan values have appeared because the outliers have been deleted and then concatenated again with encoded columns. It would be better if first encoding and then removing outliers could be performed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d75bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
